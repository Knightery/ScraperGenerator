#!/usr/bin/env python3
"""
Generated by AI Navigator
URL: https://archgroup.wd1.myworkdayjobs.com/careers/?q=summer%20internship&locationCountry=29247e57dbaf46fb855b224e03170bc7&workerSubType=2c14c19200e101019813042e39800000
Generated at: 2025-10-06T19:36:24.526516
"""

import logging
import sys
import os

# Add the parent directory to the path to import our modules
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from playwright_scraper import PlaywrightScraperSync
from supabase_database import SupabaseDatabaseManager

def setup_logging():
    """Setup logging for the scraper."""
    import os
    os.makedirs('logs', exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(f'logs/arch_insurance_international_scraper.log'),
            logging.StreamHandler()
        ]
    )

def get_scraper_config():
    """Get the scraper configuration for {company_name}."""
    return {
        'company_name': 'Arch Insurance International',
        'scrape_url': 'https://archgroup.wd1.myworkdayjobs.com/careers/?q=summer%20internship&locationCountry=29247e57dbaf46fb855b224e03170bc7&workerSubType=2c14c19200e101019813042e39800000',
        'job_container_selector': 'ul[aria-label="Page 1 of 1"] > li.css-1q2dra3',
        'title_selector': 'h3 > a[data-automation-id="jobTitle"]',
        'url_selector': 'h3 > a[data-automation-id="jobTitle"]',
        'description_selector': '',
        'location_selector': 'div[data-automation-id="locations"] dd.css-129m7dg',
        'requirements_selector': '',
        'pagination_selector': '',
        'has_dynamic_loading': True,
        'search_required': False,
        'search_input_selector': '',
        'search_submit_selector': '',
        'search_query': 'intern',
        'text_filter_keywords': '',
        'max_pages': 999  # Unlimited - will stop automatically based on end conditions
    }

def main():
    """Main scraper function."""
    setup_logging()
    logger = logging.getLogger(__name__)
    
    logger.info("Starting Arch Insurance International job scraper...")
    
    config = get_scraper_config()
    
    # Initialize database-enabled scraper
    scraper = PlaywrightScraperSync(use_database=True)
    db_manager = SupabaseDatabaseManager()
    
    # Get company info from database
    company = db_manager.get_company_by_name('Arch Insurance International')
    if not company:
        logger.error("Company '{company_name}' not found in database")
        print("Error: Company not found in database. Please add the company first.")
        return
    
    # Scrape jobs and get filtered HTML
    jobs, filtered_html = scraper.scrape_jobs(config['scrape_url'], config)
    
    if jobs:
        logger.info(f"Successfully scraped {len(jobs)} jobs from 'Arch Insurance International'")
        
        # Print summary
        print(f"\\n=== SCRAPING RESULTS ===")
        print(f"Company: 'Arch Insurance International'")
        print(f"URL: 'https://archgroup.wd1.myworkdayjobs.com/careers/?q=summer%20internship&locationCountry=29247e57dbaf46fb855b224e03170bc7&workerSubType=2c14c19200e101019813042e39800000'")
        print(f"Jobs found: {len(jobs)}")
        print(f"Jobs saved to database: jobs.db")
        
        # Show sample jobs
        print(f"\\n=== SAMPLE JOBS ===")
        for i, job in enumerate(jobs[:3], 1):
            print(f"{i}. {job.get('title', 'No title')}")
            print(f"   Location: {job.get('location', 'Not specified')}")
            print(f"   URL: {job.get('url', 'No URL')}")
            print()
        
    else:
        logger.warning("No jobs found - scraper may need adjustment")
        print("No jobs found. The scraper configuration may need to be adjusted.")
        
        # Log failed scraper execution
        db_manager.log_scraper_execution(
            company['id'], 
            0, 
            success=False,
            error_message="No jobs found"
        )

if __name__ == "__main__":
    main()
